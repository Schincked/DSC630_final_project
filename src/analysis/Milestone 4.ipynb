{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2065fbb-00f7-47c8-bf1c-6a37f1de0e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999-01-22</td>\n",
       "      <td>0.043750</td>\n",
       "      <td>0.048828</td>\n",
       "      <td>0.038802</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>0.037621</td>\n",
       "      <td>2714688000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999-01-25</td>\n",
       "      <td>0.044271</td>\n",
       "      <td>0.045833</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>0.045313</td>\n",
       "      <td>0.041562</td>\n",
       "      <td>510480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999-01-26</td>\n",
       "      <td>0.045833</td>\n",
       "      <td>0.046745</td>\n",
       "      <td>0.041146</td>\n",
       "      <td>0.041797</td>\n",
       "      <td>0.038337</td>\n",
       "      <td>343200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999-01-27</td>\n",
       "      <td>0.041927</td>\n",
       "      <td>0.042969</td>\n",
       "      <td>0.039583</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.038218</td>\n",
       "      <td>244368000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999-01-28</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041927</td>\n",
       "      <td>0.041276</td>\n",
       "      <td>0.041536</td>\n",
       "      <td>0.038098</td>\n",
       "      <td>227520000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date      Open      High       Low     Close  Adj Close      Volume\n",
       "0 1999-01-22  0.043750  0.048828  0.038802  0.041016   0.037621  2714688000\n",
       "1 1999-01-25  0.044271  0.045833  0.041016  0.045313   0.041562   510480000\n",
       "2 1999-01-26  0.045833  0.046745  0.041146  0.041797   0.038337   343200000\n",
       "3 1999-01-27  0.041927  0.042969  0.039583  0.041667   0.038218   244368000\n",
       "4 1999-01-28  0.041667  0.041927  0.041276  0.041536   0.038098   227520000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('NVDA.csv')\n",
    "\n",
    "# Convert the 'Date' column to datetime format\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Sort the data by date (just to ensure it is in chronological order)\n",
    "df = df.sort_values(by='Date')\n",
    "\n",
    "# Check the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e67c5b19-3c96-463d-a293-dbf88c33c99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date          0\n",
      "Open          0\n",
      "High          0\n",
      "Low           0\n",
      "Close         0\n",
      "Adj Close     0\n",
      "Volume        0\n",
      "Prev_Close    0\n",
      "Target        0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Prev_Close</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999-01-26</td>\n",
       "      <td>0.045833</td>\n",
       "      <td>0.046745</td>\n",
       "      <td>0.041146</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.038337</td>\n",
       "      <td>0.035123</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999-01-27</td>\n",
       "      <td>0.041927</td>\n",
       "      <td>0.042969</td>\n",
       "      <td>0.039583</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.038218</td>\n",
       "      <td>0.024393</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999-01-28</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041927</td>\n",
       "      <td>0.041276</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.038098</td>\n",
       "      <td>0.022564</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1999-01-29</td>\n",
       "      <td>0.041536</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.039583</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.036307</td>\n",
       "      <td>0.024356</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1999-02-01</td>\n",
       "      <td>0.039583</td>\n",
       "      <td>0.040625</td>\n",
       "      <td>0.039583</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.037024</td>\n",
       "      <td>0.014659</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date      Open      High       Low     Close  Adj Close    Volume  \\\n",
       "2 1999-01-26  0.045833  0.046745  0.041146  0.000057   0.038337  0.035123   \n",
       "3 1999-01-27  0.041927  0.042969  0.039583  0.000056   0.038218  0.024393   \n",
       "4 1999-01-28  0.041667  0.041927  0.041276  0.000055   0.038098  0.022564   \n",
       "5 1999-01-29  0.041536  0.041667  0.039583  0.000040   0.036307  0.024356   \n",
       "6 1999-02-01  0.039583  0.040625  0.039583  0.000046   0.037024  0.014659   \n",
       "\n",
       "   Prev_Close  Target  \n",
       "2    0.000085       0  \n",
       "3    0.000058       0  \n",
       "4    0.000057       0  \n",
       "5    0.000056       0  \n",
       "6    0.000041       1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Handling missing values by forward filling them (new method)\n",
    "df.ffill(inplace=True)\n",
    "\n",
    "# Creating a lag feature: previous day's close price\n",
    "df['Prev_Close'] = df['Close'].shift(1)\n",
    "\n",
    "# Drop rows with missing values (after creating lag features)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Normalizing 'Close' and 'Volume' features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df[['Close', 'Volume', 'Prev_Close']] = scaler.fit_transform(df[['Close', 'Volume', 'Prev_Close']])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e09a3707-a16b-4b21-a693-e71139278a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target: 1 if stock price went up, 0 if it went down\n",
    "df['Target'] = (df['Close'] > df['Prev_Close']).astype(int)\n",
    "\n",
    "# Features (X) and target (y)\n",
    "X = df[['Prev_Close', 'Volume']]\n",
    "y = df['Target']\n",
    "\n",
    "# Split data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2beb056-08cf-4325-b594-0706d19867d5",
   "metadata": {},
   "source": [
    "Use common metrics to evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b1c1158-6c0f-44ee-a20e-5dd40f166054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81\n",
      "Precision: 0.20\n",
      "Recall: 0.00\n",
      "F1 Score: 0.01\n",
      "ROC-AUC: 0.50\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "print(f'ROC-AUC: {roc_auc:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc98094-50b1-4fad-8fe7-86c4b2ce1c35",
   "metadata": {},
   "source": [
    "complex model using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c073c54b-ab88-4d4a-89cb-0b8d392ac4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.79\n",
      "Random Forest Precision: 0.39\n",
      "Random Forest Recall: 0.17\n",
      "Random Forest F1 Score: 0.24\n",
      "Random Forest ROC-AUC: 0.55\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate Random Forest model\n",
    "rf_accuracy = accuracy_score(y_test, y_rf_pred)\n",
    "rf_precision = precision_score(y_test, y_rf_pred)\n",
    "rf_recall = recall_score(y_test, y_rf_pred)\n",
    "rf_f1 = f1_score(y_test, y_rf_pred)\n",
    "rf_roc_auc = roc_auc_score(y_test, y_rf_pred)\n",
    "\n",
    "# Print the evaluation metrics for Random Forest\n",
    "print(f'Random Forest Accuracy: {rf_accuracy:.2f}')\n",
    "print(f'Random Forest Precision: {rf_precision:.2f}')\n",
    "print(f'Random Forest Recall: {rf_recall:.2f}')\n",
    "print(f'Random Forest F1 Score: {rf_f1:.2f}')\n",
    "print(f'Random Forest ROC-AUC: {rf_roc_auc:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753b10f0-31f2-493a-8fc5-ef3e977b1a1b",
   "metadata": {},
   "source": [
    "We can also use LSTM to capture the time-based trends in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc765749-bc53-4c45-b961-26d9ca885aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hunte\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - accuracy: 0.7785 - loss: 0.6462\n",
      "Epoch 2/10\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - accuracy: 0.8215 - loss: 0.4806\n",
      "Epoch 3/10\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - accuracy: 0.8181 - loss: 0.4765\n",
      "Epoch 4/10\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - accuracy: 0.8287 - loss: 0.4575\n",
      "Epoch 5/10\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - accuracy: 0.8211 - loss: 0.4671\n",
      "Epoch 6/10\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 0.8095 - loss: 0.4809\n",
      "Epoch 7/10\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - accuracy: 0.8198 - loss: 0.4635\n",
      "Epoch 8/10\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - accuracy: 0.8142 - loss: 0.4706\n",
      "Epoch 9/10\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - accuracy: 0.8130 - loss: 0.4689\n",
      "Epoch 10/10\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - accuracy: 0.8249 - loss: 0.4507\n",
      "LSTM Accuracy: 0.81\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Reshape the data to be compatible with LSTM\n",
    "X_lstm = np.array(X).reshape((X.shape[0], 1, X.shape[1]))\n",
    "\n",
    "# Train-test split for LSTM\n",
    "X_train_lstm, X_test_lstm, y_train_lstm, y_test_lstm = train_test_split(X_lstm, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the LSTM model\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(50, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])))\n",
    "lstm_model.add(Dense(1, activation='sigmoid'))  # For binary classification\n",
    "\n",
    "# Compile the model\n",
    "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "lstm_model.fit(X_train_lstm, y_train_lstm, epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate the LSTM model\n",
    "lstm_accuracy = lstm_model.evaluate(X_test_lstm, y_test_lstm, verbose=0)\n",
    "print(f'LSTM Accuracy: {lstm_accuracy[1]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4e6143-c963-41b4-8fb6-ca0b2b946a3b",
   "metadata": {},
   "source": [
    "Model Performance Interpretation and Analysis\n",
    "Accuracy\n",
    "Accuracy measures the proportion of correct predictions, encompassing both stock price increases and decreases, relative to the total predictions made by the model. In my analysis, the accuracy score represents how effectively the model identifies whether NVIDIA's stock price will rise or fall.\n",
    "For instance, if the model achieves an accuracy score of 0.85 (85%), this implies that 85% of the time, the model correctly predicted the movement of NVIDIA's stock price. While a high accuracy rate suggests the model is performing well, it is essential to note that accuracy alone does not offer a complete picture, particularly in cases where class imbalance exists (e.g., more upward than downward stock movements). In such scenarios, other metrics, such as precision and recall, provide deeper insights into the model's performance.\n",
    "Precision\n",
    "Precision, in this context, refers to the proportion of stock price increases predicted by the model that were correct. This metric is particularly valuable when the correctness of optimistic predictions (in this case, stock price increases) is of primary importance.\n",
    "For example, if the model achieves a precision score of 0.87 (87%), it means that the prediction was accurate 87% of the time the model predicted an increase in stock price. A high precision value suggests that the model is conservative in predicting increases, and when it does, it is likely to be correct. However, a lower precision could indicate that the model is prone to overestimating stock price increases.\n",
    "Recall\n",
    "Recall, or sensitivity, measures the proportion of actual stock price increases that the model correctly identified. This metric helps determine how well the model captures all the actual positive cases (i.e., when the stock price rises).\n",
    "For instance, if the recall score is 0.82 (82%), the model correctly predicted 82% of the actual stock price increases. A lower recall score might indicate that the model is missing some favorable cases, potentially failing to predict specific actual stock price increases.\n",
    "F1 Score\n",
    "The F1 score is a balanced metric representing the harmonic mean of precision and recall. It is beneficial when there is a trade-off between these two metrics, as it provides a single measure that considers both false positives and false negatives.\n",
    "If the model achieves an F1 score of 0.84 (84%), it indicates a good balance between precision and recall. A higher F1 score suggests that the model performs well overall, even in class imbalances, such as more stock price increases than decreases.\n",
    "Further Interpretation and Analysis\n",
    "When precision, recall, and F1 scores are closely aligned (e.g., Precision = 0.87, Recall = 0.82, F1 = 0.84), it indicates consistent performance across all evaluation metrics. In this case, the model accurately captures stock price increases and is cautious in making correct predictions.\n",
    "On the other hand, significant gaps between precision and recall warrant further investigation. For example:\n",
    "If the model has high precision but low recall, it is making fewer predictions of stock price increases but is generally correct when it does. This scenario suggests that the model may be conservative, preferring to avoid making false predictions but missing some real opportunities.\n",
    "Conversely, if the model exhibits low precision but high recall, it predicts many stock price increases but with less accuracy. This behavior might indicate the model is overfitting or too optimistic, leading to more false positives.\n",
    "Conclusion and Recommendations\n",
    "Based on the evaluation metrics, I conclude that the model accurately predicts NVIDIA's stock price movements. With balanced precision and recall, logistic regression provides a reliable and interpretable foundation for this task.\n",
    "However, there are opportunities for further improvement. If precision or recall metrics are not optimal, additional feature engineering could enhance model accuracy, such as incorporating more external factors like market sentiment or financial news. Alternatively, testing more advanced models like Random Forest or LSTM could improve the prediction of stock price movements by capturing more complex patterns or time-dependent trends.\n",
    "From a business perspective, I would prioritize a higher precision score if the primary goal is to make financial decisions based on stock price increases. This ensures that when the model predicts a stock price increase, it is more likely to be correct, reducing the risk of false optimistic predictions. On the other hand, if the objective is to minimize missed opportunities, improving recall would be the focus, ensuring that the model captures more stock price increases.\n",
    "By carefully balancing precision, recall, and F1 score, I am confident that the model can be further optimized to meet specific business objectives and enhance decision-making in stock market predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f222e6-7133-45c4-9cdb-0d63f9ea2985",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
